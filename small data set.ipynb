{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import more_itertools\n",
    "import math\n",
    "import random as rd\n",
    "from time import perf_counter\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 10)\n",
    "df = pd.read_csv(\"s.txt\", index_col = False, sep=\"\\s+\", header=None, dtype=np.float64)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stop Forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dis(data, feat_opt):\n",
    "    \n",
    "    row = data.shape[0]\n",
    "    i = 0\n",
    "    accuracy_counter = 0\n",
    "\n",
    "    start_time = perf_counter()*1000\n",
    "    \n",
    "    while i < row:\n",
    "        \n",
    "        idx_predicted_class = 0\n",
    "        nearest_value = np.inf\n",
    "    \n",
    "        j = 0\n",
    "        while j < row:\n",
    "            if j != i:\n",
    "                lpnorm = 0\n",
    "                for feat_idx in feat_opt: \n",
    "                    lpnorm += pow((data.iloc[i,feat_idx] - data.iloc[j,feat_idx]),2)\n",
    "\n",
    "                #print(f\"i: {i}, j: {j}, lpnorm: {lpnorm}\")\n",
    "                if lpnorm < nearest_value:\n",
    "                    nearest_value = lpnorm\n",
    "                    idx_predicted_class = j\n",
    "                    \n",
    "            j+= 1\n",
    "        \n",
    "        if data.iloc[i,0] == data.iloc[idx_predicted_class,0]:\n",
    "            accuracy_counter += 1\n",
    "            \n",
    "        i+=1\n",
    "    \n",
    "    stop_time = perf_counter()*1000\n",
    "    performance_time = ((stop_time - start_time)/row)\n",
    "    \n",
    "    predict_accuracy = (float(accuracy_counter)/row)\n",
    "    return (performance_time, predict_accuracy)\n",
    "\n",
    "#forward selection = 1\n",
    "#backward selection = 0\n",
    "\n",
    "flag = 1\n",
    "\n",
    "fearly_stop_performance = pd.DataFrame(columns= ['Time','Average accuracy','Feature set'])\n",
    "feature_used = []\n",
    "\n",
    "def display(fu, fa, tm):\n",
    "    print(f\"testing feature {fu} feature accuracy: {round(fa*100,2)}%, performance time {round(tm,2)}ms\")\n",
    "    \n",
    "i = 1\n",
    "chance = 0.5\n",
    "\n",
    "best_accuracy_collector = chance # current list\n",
    "best_accuracy = chance # testing the current list \n",
    "\n",
    "if flag:\n",
    "    feature_collector = []\n",
    "\n",
    "    while i < df.shape[1]:\n",
    "\n",
    "        if i not in feature_collector:\n",
    "\n",
    "            feature_used = feature_collector + [i]\n",
    "            time_measurement, feature_accuracy = dis(df, feature_used)\n",
    "            temp_val_holder = [time_measurement, feature_accuracy, feature_used]\n",
    "            display(feature_used, feature_accuracy, time_measurement)\n",
    "\n",
    "            if feature_accuracy > best_accuracy :\n",
    "                best_feature = i\n",
    "                best_accuracy = feature_accuracy\n",
    "\n",
    "        fearly_stop_performance.loc[len(fearly_stop_performance)] = temp_val_holder\n",
    "\n",
    "        i+= 1\n",
    "\n",
    "        if i == df.shape[1]: # end of the feature no more features to loop\n",
    "            if best_accuracy > best_accuracy_collector:\n",
    "                feature_collector.append(best_feature)\n",
    "                best_accuracy_collector = best_accuracy\n",
    "                i = 1 #restart the loop for the features\n",
    "else:\n",
    "\n",
    "    feature_collector = list(range(1,df.shape[1]))\n",
    "\n",
    "    while i < df.shape[1]:\n",
    "\n",
    "        if i in feature_collector:\n",
    "\n",
    "            feature_used = feature_collector.copy()\n",
    "            feature_used.remove(i)\n",
    "\n",
    "            time_measurement, feature_accuracy = dis(df, feature_used)\n",
    "            temp_val_holder = [time_measurement, feature_accuracy, feature_used]\n",
    "            display(feature_used, feature_accuracy, time_measurement)\n",
    "\n",
    "            if feature_accuracy > best_accuracy :\n",
    "                best_feature = i\n",
    "                best_accuracy = feature_accuracy\n",
    "\n",
    "        fearly_stop_performance.loc[len(fearly_stop_performance)] = temp_val_holder\n",
    "\n",
    "        i+= 1\n",
    "\n",
    "        if i == df.shape[1]: # end of the feature no more features to loop\n",
    "            if best_accuracy > best_accuracy_collector:\n",
    "                feature_collector.remove(best_feature)\n",
    "                best_accuracy_collector = best_accuracy\n",
    "                i = 1 #restart the loop for the feature}s\n",
    "print(f\"Best Accuracy and Feature: {round(fearly_stop_performance.loc[fearly_stop_performance['Average accuracy'].idxmax()][1],2)*100, fearly_stop_performance.loc[fearly_stop_performance['Average accuracy'].idxmax()][2]}\")\n",
    "print(f\"Total time taken: {round((sum(fearly_stop_performance.iloc[:,0])/1000),2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward stop backward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis(data, feat_opt):\n",
    "    \n",
    "    row = data.shape[0]\n",
    "    i = 0\n",
    "    accuracy_counter = 0\n",
    "\n",
    "    start_time = perf_counter()*1000\n",
    "    \n",
    "    while i < row:\n",
    "        \n",
    "        idx_predicted_class = 0\n",
    "        nearest_value = np.inf\n",
    "    \n",
    "        j = 0\n",
    "        while j < row:\n",
    "            if j != i:\n",
    "                lpnorm = 0\n",
    "                for feat_idx in feat_opt: \n",
    "                    lpnorm += pow((data.iloc[i,feat_idx] - data.iloc[j,feat_idx]),2)\n",
    "\n",
    "                #print(f\"i: {i}, j: {j}, lpnorm: {lpnorm}\")\n",
    "                if lpnorm < nearest_value:\n",
    "                    nearest_value = lpnorm\n",
    "                    idx_predicted_class = j\n",
    "                    \n",
    "            j+= 1\n",
    "        \n",
    "        if data.iloc[i,0] == data.iloc[idx_predicted_class,0]:\n",
    "            accuracy_counter += 1\n",
    "            \n",
    "        i+=1\n",
    "    \n",
    "    stop_time = perf_counter()*1000\n",
    "    performance_time = ((stop_time - start_time)/row)\n",
    "    \n",
    "    predict_accuracy = (float(accuracy_counter)/row)\n",
    "    return (performance_time, predict_accuracy)\n",
    "\n",
    "#forward selection = 1\n",
    "#backward selection = 0\n",
    "\n",
    "flag = 1\n",
    "\n",
    "bearly_stop_performance = pd.DataFrame(columns= ['Time','Average accuracy','Feature set'])\n",
    "feature_used = []\n",
    "\n",
    "def display(fu, fa, tm):\n",
    "    print(f\"testing feature {fu} feature accuracy: {round(fa*100,2)}%, performance time {round(tm,2)}ms\")\n",
    "    \n",
    "i = 1\n",
    "chance = 0.5\n",
    "\n",
    "best_accuracy_collector = chance # current list\n",
    "best_accuracy = chance # testing the current list \n",
    "\n",
    "if flag:\n",
    "    feature_collector = []\n",
    "\n",
    "    while i < df.shape[1]:\n",
    "\n",
    "        if i not in feature_collector:\n",
    "\n",
    "            feature_used = feature_collector + [i]\n",
    "            time_measurement, feature_accuracy = dis(df, feature_used)\n",
    "            temp_val_holder = [time_measurement, feature_accuracy, feature_used]\n",
    "            display(feature_used, feature_accuracy, time_measurement)\n",
    "\n",
    "            if feature_accuracy > best_accuracy :\n",
    "                best_feature = i\n",
    "                best_accuracy = feature_accuracy\n",
    "\n",
    "        bearly_stop_performance.loc[len(bearly_stop_performance)] = temp_val_holder\n",
    "\n",
    "        i+= 1\n",
    "\n",
    "        if i == df.shape[1]: # end of the feature no more features to loop\n",
    "            if best_accuracy > best_accuracy_collector:\n",
    "                feature_collector.append(best_feature)\n",
    "                best_accuracy_collector = best_accuracy\n",
    "                i = 1 #restart the loop for the features\n",
    "else:\n",
    "\n",
    "    feature_collector = list(range(1,df.shape[1]))\n",
    "\n",
    "    while i < df.shape[1]:\n",
    "\n",
    "        if i in feature_collector:\n",
    "\n",
    "            feature_used = feature_collector.copy()\n",
    "            feature_used.remove(i)\n",
    "\n",
    "            time_measurement, feature_accuracy = dis(df, feature_used)\n",
    "            temp_val_holder = [time_measurement, feature_accuracy, feature_used]\n",
    "            display(feature_used, feature_accuracy, time_measurement)\n",
    "\n",
    "            if feature_accuracy > best_accuracy :\n",
    "                best_feature = i\n",
    "                best_accuracy = feature_accuracy\n",
    "\n",
    "        bearly_stop_performance.loc[len(bearly_stop_performance)] = temp_val_holder\n",
    "\n",
    "        i+= 1\n",
    "\n",
    "        if i == df.shape[1]: # end of the feature no more features to loop\n",
    "            if best_accuracy > best_accuracy_collector:\n",
    "                feature_collector.remove(best_feature)\n",
    "                best_accuracy_collector = best_accuracy\n",
    "                i = 1 #restart the loop for the feature}s\n",
    "print(f\"Best Accuracy and Feature: {round(bearly_stop_performance.loc[bearly_stop_performance['Average accuracy'].idxmax()][1],2)*100, bearly_stop_performance.loc[bearly_stop_performance['Average accuracy'].idxmax()][2]}\")\n",
    "print(f\"Total time taken: {round((sum(bearly_stop_performance.iloc[:,0])/1000),2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without early stop forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis(data, feat_opt):\n",
    "    \n",
    "    row = data.shape[0]\n",
    "    i = 0\n",
    "    accuracy_counter = 0\n",
    "\n",
    "    start_time = perf_counter()*1000\n",
    "    \n",
    "    while i < row:\n",
    "        \n",
    "        idx_predicted_class = 0\n",
    "        nearest_value = np.inf\n",
    "    \n",
    "        j = 0\n",
    "        while j < row:\n",
    "            if j != i:\n",
    "                lpnorm = 0\n",
    "                for feat_idx in feat_opt: \n",
    "                    lpnorm += pow((data.iloc[i,feat_idx] - data.iloc[j,feat_idx]),2)\n",
    "\n",
    "                #print(f\"i: {i}, j: {j}, lpnorm: {lpnorm}\")\n",
    "                if lpnorm < nearest_value:\n",
    "                    nearest_value = lpnorm\n",
    "                    idx_predicted_class = j\n",
    "                    \n",
    "            j+= 1\n",
    "        \n",
    "        if data.iloc[i,0] == data.iloc[idx_predicted_class,0]:\n",
    "            accuracy_counter += 1\n",
    "            \n",
    "        i+=1\n",
    "    \n",
    "    stop_time = perf_counter()*1000\n",
    "    performance_time = ((stop_time - start_time)/row)\n",
    "    \n",
    "    predict_accuracy = (float(accuracy_counter)/row)\n",
    "    return (performance_time, predict_accuracy)\n",
    "\n",
    "#forward selection = 1\n",
    "#backward selection = 0\n",
    "\n",
    "flag = 1\n",
    "\n",
    "wesfs_performance = pd.DataFrame(columns= ['Time','Average accuracy','Feature set'])\n",
    "feature_used = []\n",
    "\n",
    "def display(fu, fa, tm):\n",
    "    print(f\"testing feature {fu} feature accuracy: {round(fa*100,2)}%, performance time {round(tm,2)}ms\")\n",
    "    \n",
    "i = 1\n",
    "\n",
    "best_accuracy_collector = -1 # current list\n",
    "best_accuracy = -1 # testing the current list \n",
    "\n",
    "if flag:\n",
    "    feature_collector = []\n",
    "\n",
    "    while i < df.shape[1]:\n",
    "\n",
    "        if i not in feature_collector:\n",
    "\n",
    "            feature_used = feature_collector + [i]\n",
    "            time_measurement, feature_accuracy = dis(df, feature_used)\n",
    "            temp_val_holder = [time_measurement, feature_accuracy, feature_used]\n",
    "            display(feature_used, feature_accuracy, time_measurement)\n",
    "\n",
    "            if feature_accuracy > best_accuracy :\n",
    "                best_feature = i\n",
    "                best_accuracy = feature_accuracy\n",
    "\n",
    "        wesfs_performance.loc[len(wesfs_performance)] = temp_val_holder\n",
    "\n",
    "        i+= 1\n",
    "\n",
    "        if i == df.shape[1]: # end of the feature no more features to loop\n",
    "            \n",
    "            if best_accuracy > best_accuracy_collector:\n",
    "                \n",
    "                feature_collector.append(best_feature)\n",
    "                best_accuracy_collector = best_accuracy\n",
    "                i = 1 #restart the loop for the features\n",
    "                best_accuracy = -1\n",
    "                \n",
    "            else: #accuracy is not going to get better here\n",
    "                feature_collector.append(best_feature)\n",
    "                if len(feature_collector) < df.shape[1]:\n",
    "                    best_accuracy = -1\n",
    "                    i = 1\n",
    "                \n",
    "                \n",
    "else:\n",
    "\n",
    "    feature_collector = list(range(1,df.shape[1]))\n",
    "\n",
    "    while i < df.shape[1]:\n",
    "\n",
    "        if i in feature_collector:\n",
    "\n",
    "            feature_used = feature_collector.copy()\n",
    "            feature_used.remove(i)\n",
    "\n",
    "            time_measurement, feature_accuracy = dis(df, feature_used)\n",
    "            temp_val_holder = [time_measurement, feature_accuracy, feature_used]\n",
    "            display(feature_used, feature_accuracy, time_measurement)\n",
    "\n",
    "            if feature_accuracy > best_accuracy :\n",
    "                best_feature = i\n",
    "                best_accuracy = feature_accuracy\n",
    "\n",
    "        wesfs_performance.loc[len(wesfs_performance)] = temp_val_holder\n",
    "\n",
    "        i+= 1\n",
    "\n",
    "        if i == df.shape[1]: # end of the feature no more features to loop\n",
    "            \n",
    "            if best_accuracy > best_accuracy_collector:\n",
    "                feature_collector.remove(best_feature)\n",
    "                best_accuracy_collector = best_accuracy\n",
    "                i = 1 #restart the loop for the feature}s\n",
    "                best_accuracy = -1 \n",
    "                \n",
    "            else:\n",
    "                \n",
    "                feature_collector.remove(best_feature)\n",
    "                \n",
    "                if len(feature_collector) > 0: #accuracy is not going to get better here\n",
    "                    best_accuracy = -1\n",
    "                    i = 1\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "print(f\"Best Accuracy and Feature: {round(wesfs_performance.loc[wesfs_performance['Average accuracy'].idxmax()][1],2)*100, wesfs_performance.loc[wesfs_performance['Average accuracy'].idxmax()][2]}\")\n",
    "print(f\"Total time taken: {round((sum(wesfs_performance.iloc[:,0])/1000),2)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without early stop backward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis(data, feat_opt):\n",
    "    \n",
    "    row = data.shape[0]\n",
    "    i = 0\n",
    "    accuracy_counter = 0\n",
    "\n",
    "    start_time = perf_counter()*1000\n",
    "    \n",
    "    while i < row:\n",
    "        \n",
    "        idx_predicted_class = 0\n",
    "        nearest_value = np.inf\n",
    "    \n",
    "        j = 0\n",
    "        while j < row:\n",
    "            if j != i:\n",
    "                lpnorm = 0\n",
    "                for feat_idx in feat_opt: \n",
    "                    lpnorm += pow((data.iloc[i,feat_idx] - data.iloc[j,feat_idx]),2)\n",
    "\n",
    "                #print(f\"i: {i}, j: {j}, lpnorm: {lpnorm}\")\n",
    "                if lpnorm < nearest_value:\n",
    "                    nearest_value = lpnorm\n",
    "                    idx_predicted_class = j\n",
    "                    \n",
    "            j+= 1\n",
    "        \n",
    "        if data.iloc[i,0] == data.iloc[idx_predicted_class,0]:\n",
    "            accuracy_counter += 1\n",
    "            \n",
    "        i+=1\n",
    "    \n",
    "    stop_time = perf_counter()*1000\n",
    "    performance_time = ((stop_time - start_time)/row)\n",
    "    \n",
    "    predict_accuracy = (float(accuracy_counter)/row)\n",
    "    return (performance_time, predict_accuracy)\n",
    "\n",
    "#forward selection = 1\n",
    "#backward selection = 0\n",
    "\n",
    "flag = 0\n",
    "\n",
    "wesbs_performance = pd.DataFrame(columns= ['Time','Average accuracy','Feature set'])\n",
    "feature_used = []\n",
    "\n",
    "def display(fu, fa, tm):\n",
    "    print(f\"testing feature {fu} feature accuracy: {round(fa*100,2)}%, performance time {round(tm,2)}ms\")\n",
    "    \n",
    "i = 1\n",
    "\n",
    "best_accuracy_collector = -1 # current list\n",
    "best_accuracy = -1 # testing the current list \n",
    "\n",
    "if flag:\n",
    "    feature_collector = []\n",
    "\n",
    "    while i < df.shape[1]:\n",
    "\n",
    "        if i not in feature_collector:\n",
    "\n",
    "            feature_used = feature_collector + [i]\n",
    "            time_measurement, feature_accuracy = dis(df, feature_used)\n",
    "            temp_val_holder = [time_measurement, feature_accuracy, feature_used]\n",
    "            display(feature_used, feature_accuracy, time_measurement)\n",
    "\n",
    "            if feature_accuracy > best_accuracy :\n",
    "                best_feature = i\n",
    "                best_accuracy = feature_accuracy\n",
    "\n",
    "        wesbs_performance.loc[len(wesbs_performance)] = temp_val_holder\n",
    "\n",
    "        i+= 1\n",
    "\n",
    "        if i == df.shape[1]: # end of the feature no more features to loop\n",
    "            \n",
    "            if best_accuracy > best_accuracy_collector:\n",
    "                \n",
    "                feature_collector.append(best_feature)\n",
    "                best_accuracy_collector = best_accuracy\n",
    "                i = 1 #restart the loop for the features\n",
    "                best_accuracy = -1\n",
    "                \n",
    "            else: #accuracy is not going to get better here\n",
    "                feature_collector.append(best_feature)\n",
    "                if len(feature_collector) < df.shape[1]:\n",
    "                    best_accuracy = -1\n",
    "                    i = 1\n",
    "                \n",
    "                \n",
    "else:\n",
    "\n",
    "    feature_collector = list(range(1,df.shape[1]))\n",
    "\n",
    "    while i < df.shape[1]:\n",
    "\n",
    "        if i in feature_collector:\n",
    "\n",
    "            feature_used = feature_collector.copy()\n",
    "            feature_used.remove(i)\n",
    "\n",
    "            time_measurement, feature_accuracy = dis(df, feature_used)\n",
    "            temp_val_holder = [time_measurement, feature_accuracy, feature_used]\n",
    "            display(feature_used, feature_accuracy, time_measurement)\n",
    "\n",
    "            if feature_accuracy > best_accuracy :\n",
    "                best_feature = i\n",
    "                best_accuracy = feature_accuracy\n",
    "\n",
    "        wesbs_performance.loc[len(wesbs_performance)] = temp_val_holder\n",
    "\n",
    "        i+= 1\n",
    "\n",
    "        if i == df.shape[1]: # end of the feature no more features to loop\n",
    "            \n",
    "            if best_accuracy > best_accuracy_collector:\n",
    "                feature_collector.remove(best_feature)\n",
    "                best_accuracy_collector = best_accuracy\n",
    "                i = 1 #restart the loop for the feature}s\n",
    "                best_accuracy = -1 \n",
    "                \n",
    "            else:\n",
    "                \n",
    "                feature_collector.remove(best_feature)\n",
    "                \n",
    "                if len(feature_collector) > 0: #accuracy is not going to get better here\n",
    "                    best_accuracy = -1\n",
    "                    i = 1\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "print(f\"Best Accuracy and Feature: {round(wesbs_performance.loc[wesbs_performance['Average accuracy'].idxmax()][1],2)*100, wesbs_performance.loc[wesbs_performance['Average accuracy'].idxmax()][2]}\")\n",
    "print(f\"Total time taken: {round((sum(wesbs_performance.iloc[:,0])/1000),2)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total time taken: {round((sum(performance.iloc[:,0])/1000),2)}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
